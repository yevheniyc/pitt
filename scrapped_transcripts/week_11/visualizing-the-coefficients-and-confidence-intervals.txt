Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/RYh5u/visualizing-the-coefficients-and-confidence-intervals

English
The name of the coefficient is on the y axis, the value is on the x axis.
Again, matplotlib doesn't name the axes.
So let's put in, set the axis labels.
Ax.set_xlabel is the coefficient value.
I will typically leave the y axis label blank because I think it
just takes up space to write coefficient name.
You can leave it as perfectly fine, but
I actually often just leave it blank because I know this is x.
You see this interval, this error bar?
This is our approximation to the 95% confidence interval around the estimate.
By default, the estimates are connected by a line.
Well, I don't want to show the line, so
I'm going to change the format with the fmt argument.
I want to use a circle.
So I put in a 0 in quote, and then I will typically make the color black.
I can force the edge color, that's the error bar color,
to be something different, but I will typically make it also black.
You can even change the edge line width,
you can make it very thin, you can make it very thick.
So I typically do something between 1 to 3 and
you can change the marker size with the ms argument.
I will make this usually between 3 to 10,
depending on the application.
Now, we could be done here, but it's always important and
useful to include a vertical reference line at 0.
This is done with the ax.axvline method.
This is a vertical line from the axis.
The argument x=0 specifies the location on the x axis for the line.
By default we get a solid line that is gray or sorry,
that is blue but I like to change the line style to a dashed line.
I like to make the line width larger and
then set the color to be gray.
Now why am I highlighting this reference point of a coefficient value of 0?
If I go back to the data that we created,
this is the HTML report for the earlier
example where we made this data set.
We made these nine random points.
Remember the trend is linearly related to the input x,
and remember I specified the value of the slope.
Well, what we just did with fitting
the model by calling the smf.ols function,
we have estimated the slope.
Our estimate for the slope is a negative number,
but we need to express how confident we are that this slope is negative,
because if the slope is negative on average,
the output will decrease as the input increases.
How can we express our confidence or trustworthiness of this slope?
The 95% confidence interval?
If the 95% confidence interval does not contain 0,
we are confident in the sign of the slope,
SIGN, do you see how this confidence
interval does not contain 0?
We are therefore confident that
the slope is negative in this case,
that idea of how confident are you
in the sign, the confidence or
trustworthiness of the sign,
negative or positive of the slope
is typically expressed via the p value.
If the p value is less than 0.05,
that means the 95% confidence
interval does not contain 0.
If you look at the intercept, its p value is greater than 0.05 and
its 95% confidence interval does contain 0.
But what matters is the input that we are using,
because this input is expressing how the average is changing.
The fact that we are confident that the slope is negative means we
are confident that the average output is decreasing as the input is increasing.
So again, if you're ever wondering what the p value means,
it's fully explained by this visualization.
If that 95% confidence interval does not contain 0,
then we are confident in the sign whether that sign is negative or positive.
And so if we were working on an example with a positive slope,
the 95% confidence interval would look something like this,
it would be far away on the right hand side.
Now, I mentioned before that this in truth is just
an approximation because I use two times the standard error.
And this is really good when you are working with a large data set,
many many samples or many many rows.
I will typically use the fitted stats models
object directly to create the above figure.
So we'll recreate this whole thing from scratch so you see it again.
Figure ax = plt.subplots.
Then the 95% confidence interval or
95% CI approximation around
the estimate ax.errorbar,
axis labels, ax.set_xlabel
coefficient value plt.show and
the reference line at 0 ax.axvline.
Okay, for the errorbar,
y = lm_fit.params index,
x = lm_fit.params x error,
xerr is two times lm_fit.bse,
and then the format 0,
color black, edge color black,
edge line width, I used 4,
I used 2, marker size 10,
axvline x = 0, linestyle --
line width for color = gray.
Okay, so this is using the fitted object directly, and it's pretty easy to use.
All you need is just the params and the bse attribute.