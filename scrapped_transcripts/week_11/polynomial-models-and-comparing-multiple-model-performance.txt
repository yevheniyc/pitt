Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/SstbH/polynomial-models-and-comparing-multiple-model-performance

English
If we would examine
the ll plot between the input x and the observed output,
this negative slope that is considered to
be statistically significant is
saying the output on average
is decreasing as the input increases.
Well, do you remember when we created
the trend lines between two continuous variables?
The lmplot, and do you
remember that ribbon that was around it?
That was your 95% confidence interval.
We now know where this 95%
confidence interval comes from.
According to this model,
the input x is statistically significant,
but how well does this model perform?
Well, we can look at its r^2.
That r^2 is higher than 0.
It is generally related to the observed output more
than the intercept only model.
What's this model's RMSE,
M0d 01 one residual squared mean.
Is that value better
than the RMSE of
the intercept on model?
Well, let's calculate it and find out.
The RMSE, according to
the RMSE for the linear relationship,
however, is considered to be higher
than the intercept only models for RMSE.
If we display if we print the Mod 01 summary,
the F statistic and
the models p value is really trying to get at,
do we think this model is,
in fact, better than an intercept only model?
Well, as you can see here,
the linear relationships RMSE is
not greater than the intercept only models for RMSE,
therefore, it's considered to be doing
better than the unknown constant average.
Really, I should have been asking here, is it less?
True. It's considered to have
a lower RMSE than the unknown constant average.
But there's no reason why we need to stop,
we can also try
a quadratic or second degree polynomial model.
I'll name this one Mod 02, SMF OLS.
It has a formula.
It has data, and we apply the fit.
We need df train.
The formula, y Tilda,
x plus to raise the input to the second power,
we need the NP power function.
Np_power x, 2 is going to square the input x.
Now, we have three coefficients,
the intercept, the linear relationship,
and the squared feature.
If we use the MCF plot function,
we are now examining how statistically significant is
that squared relationship, that squared feature.
This says it's not. If we check our r^2,
that quadratic models r^2
isn't really any better than the linear relationship.
But we can also use a cubic relationship.
Let's name this one Mod 03,
SMF OLS with a formula,
a data argument.fit_data_df_train, the formula,
y tilda x+np.power x2+np.power x,
3 We are squaring the input x.
We are raising x third power or cubing.
If we apply MCF plot,
we are getting the visual summary of the coefficients.
Now, the squared feature
is still statistically insignificant,
but the cubic feature is statistically significant.
Does this model do better?
Let's check its r^2.
It does have a higher r^2
than the linear relationship model.
If we include in the residual or if we examine
the RMSE is the RMSE of
the cubic model better
than the linear relationship model?
Let's make this less than again.
We can see that true.
The cubic relationship model,
as a lower RMSE than the linear relationship model.
According to our performance metrics,
by adding in not only a squared feature,
and a cubic feature,
we are getting a better relationship of
the observed output compared to
using a linear relationship.
We could examine this figure directly
with lmplot_data equals df_train_ x = x,
y = y degree,
I even always have to confirm this.
Let me just double check.
It's order equals 3_plt_show.
This is the equivalent model we just fit,
a cubic or third degree relationship.
The second degree relationship was here, the cubic here.
We now know performance metrics we
can use to examine which ones are better.
But we will revisit
the question of which model is better later.
This video is just to introduce
these concepts and discuss how
we could go about trying
different models when we don't know the right answer.