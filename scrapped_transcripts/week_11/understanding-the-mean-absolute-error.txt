Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/PtuTq/understanding-the-mean-absolute-error

English
The RMSE is essentially the sigma
parameter that we defined when
we generated the random data.
So RMSE is represented by is trying to represent the sigma
parameter that we saw when we generated the random output.
Or another way to view it, if we go back to the prediction example,
do you remember the prediction interval?
The distance from the predictive trend to this outer prediction
interval is essentially two times the model's RMSE.
That's why it's a constant interval, but it's capturing and
representing the fundamental error of your model.
Again, this is a concept we will return to and visit in more detail in comp 21 20.
The class that comes after but the prediction interval is capturing and
representing the RMSE, the square the error of your model.
The other kind of important error metric
is the is based on the absolute error.
So if we go back to the residual, instead of squaring it,
we can apply the NPAPS function.
ABS is the absolute value.
Now we have zero negatives because we just want the absolute error.
The smaller the closer this is to zero,
the smaller the error is relative to the observed output.
We average the absolute
error to get the MAE.
The mean absolute error, or MAE,
is the average absolute error of the training data.
The MAE is less sensitive to extreme output
values because it's not squaring the error.
So, for example, let's say you have this trend here, this red line is your
predicted trend, and you have these different observed training points.
And maybe you have this one that's quote unquote extreme,
it's far away from the predicted trend.
The squared error will calculate this difference and square it so
it will explode this error relative to all of the other data points.
The absolute error treats the magnitude of this error
as of equal weight or importance as the others.
So if you have extreme output values,
you may want to focus more on the MAE than the MSE or RMSE.
Again, this is something we return back to in 21 20 in more detail.
But in summary, we have seen two types of
performance metrics for regression problems.
We have seen the general linear relationship
expressed in the predicted versus observed
figure, quantified as r squared.
We have also seen the error metrics
that summarize the errors of a model.
We can calculate those errors
based on the squared error,
which is summarized as the MSE or
RMSE, or we can calculate those
errors based on the absolute error,
which is summarized as the MAE.
Okay, so again, I hope you liked this video,
I hope it makes sense as to the kind of performance
metrics that we focus on in regression.
The previous videos that focused on interpreting the fitting
results through the coefficients and visualizing the fitting
results through predictions are an important aspect of ultimately
interpreting how much we can trust and use these models.
This video was focused on how do we quantify and
measure their performance on the training set.