Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/qa3Eq/producing-random-outputs

English
This more transparent outer ribbon is the 95% uncertainty interval,
the plus or minus two standard deviation interval around the trend.
The more opaque inner interval is the 68% uncertainty interval,
or the plus or minus one standard deviation interval.
We are summarizing the Gaussian distribution
that is located at each point at the average along this graph.
So, think of little bell curves that are sliding along that red line,
and I'm trying to draw them in as we do that here, drawing these in.
The width of those bell curves is constant because the height, as you can see,
of the ribbons are literally the same no matter the value of the input.
But where the bell curves are located is changing as
the input changes because the trend depends on the input.
Now, why did I want to show this plot besides reviewing the key assumptions?
Well, it will help put in context the data we are about to randomly generate.
So let's generate random output data.
Let's generate a small number of random output
observations at specific input values.
For simplicity, let's treat the input as not random.
The input will have values uniformly
spaced between a lower bound and upper bound.
I want to have uniformly spaced input locations between negative three and
positive three, that's what I want to do here.
Specifically, let's use nine input locations between
negative three and positive three.
I will assign these inputs to the df object, df for data frame, and
let's create that data frame using the key value pair dictionary,
following the same approach as previously, but
now the lower bound will be negative three,
the upper bound will be three, and the number will be nine.
If I scroll back up, remember we originally
used 101 evenly spaced points for x, but
I did that to support a visualization.
I wanted to have many points along this line to make
the visualization very easy to look at.
But now, I'm going to represent randomly collecting data,
and we typically don't have that much data,
even though you often hear today called the big data age.
But let's start with just nine data points.
Next, we need to calculate the mean output or
trend given the input values.
Again, follow the same procedure where the trend is a new column
which is equal to the intercept plus the slope times the input.
But now it's df, not df viz.
So I'm using the column from df and assigning a new column to df.
The output are randomly distributed
around the mean with a Gaussian or
as a as a Gaussian distribution.
This means we need to initialize and
set the seed for our random number generator.
I'm using the NumPy random.default RNG generator and
setting the seed, just like we did last week and earlier in the semester.
Let's make a new column y in the DF data frame,
which is equal to the gaussian or normal random number generator.
The mean or location is equal to the trend,
the scale or the standard deviation is my sigma,
and the size of the number of random observations
will be equal to the number of rows in the data frame DF.
So, again, just as we talked about last week, the average is not the input.
The average output is the function of the input,
the trend, the intercept plus the slope times the input.