Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/hZuSX/interpreting-the-fitting-results-and-confidence-intervals

English
Because as a reminder,
the formula of y Tilda x stands
for our math notation of the trend
is equal to intercept plus slow times input.
I call the slope Beta_1 in my math notation,
but in the summary results,
the name x, this is the coefficient that multiplies x.
This is the slope multiplying x.
The intercept is the name
for what I call Beta_0 in the math notation.
This is the value added
to the result of slope times input.
This table provides a lot of
really helpful and meaningful information
that you can work with.
The estimated coefficient, the standard error,
how trustworthy is the estimate,
the p-value, and then the 95% confidence interval.
All of these pieces of information are
useful in helping you
understand how much you can trust the result.
But if you just want to examine the estimates themselves,
the params attribute stores the coefficient estimates.
These are the estimates that minimize the sum
of squared errors, so Ln_fit.params.
Intercept.
Intercept coefficient estimate.
The slope multiplying x,
here is its coefficient estimate.
The standard error on
the estimate is contained in the.bse attribute.
Ln_fit.bse, do you see the intercept 0.37?
This is not the estimate on the intercept.
This is the intercept's standard error.
Just like how x,
0.19, this is the coefficient estimates standard error.
The standard error is what we were
calculating in all of
our simulations at the beginning of the semester.
The standard error is how much we can trust the estimate.
Essentially, we can use
the +/-1 and +/-2 standard error intervals
to know how trustworthy the estimate is.
The most common standard error interval
is the +/-2 standard error interval,
because that is approximately
equal to the 95% confidence interval.
If I take ln_fit.params-2*ln_fit.bse
, and then ln_fit.params+2*ln_fit.bse.
Let me focus on the slope.
Two standard errors less than
the estimate is the
lower bound on the 95% confidence interval.
Two times the standard error added to
the estimate is the upper bound on
the 95% confidence interval.
We are essentially 95% confident that
the coefficient is somewhere between -2 and -1.3.
Now, this piece of information,
the confidence interval is directly provided to
you on the right-hand side of the summary table.
0.025, this is the 2.5 percentile,
0.975, this is the 97.5 percentile.
The 95% confidence interval is between these two bounds.
Now, if you look closely,
the lower bound is -2.15,
and the upper bound is -1.245.
Those are slightly different compared to what we
calculated from our +/-2 times the standard error.
That is because the actual 95% confidence interval
is a slightly more difficult formula,
but when the sample size is high,
our approximation using the Gaussian becomes really good.
If you want the exact 95% confidence interval,
then you can extract it using
the C-O-N-F_I-N-T, the conf_int method.
So ln_fit.conf_int, this is a method.
Now, the result,
I think is really unfortunate,
because this result is a dataframe.
We can confirm that here by calling
the type on the result of conf_int.
It is a dataframe,
but the names are atrocious.
These names don't mean anything, 0 and 1.
Let's change the column names to
the confidence interval lower
bound and the confidence interval upper bound.
Ln_fit.conf_int.rename,
where we are renaming the columns.
This 0, if we add in a cell,
if we apply the columns attribute,
the columns are just integers.
The zero column, I'm going to rename to CI lower,
then I will rename the one column to CI upper.
CI is the shorthand for confidence interval.
Now we know the lower and upper bound of
the confidence interval on the slope is these two values.
By default, you are getting the 95% confidence interval.