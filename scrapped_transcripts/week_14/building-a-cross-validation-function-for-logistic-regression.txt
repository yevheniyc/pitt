Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/iZNMe/building-a-cross-validation-function-for-logistic-regression

English
Let's use the same strategy again.
Let's define a function that manages
the fitting and performance metric calculation
within the cross validation folds.
I'm going to define this function,
def, and name it train_and_test_logistic_with_cv().
The arguments to this function will
be very similar to what we had last week.
We have a name for the model,
we have a formula,
and we have a dataset,
which I'll call data_df
to remind me that this is a DataFrame.
Then I need the input names.
I'll call those x_names.
I need the output name.
I'll call it y_name.
I need a CV object.
You'll see at the end of this week
why I'm calling that just cv.
Then lastly, I need to specify the threshold,
and I will set that threshold to
have a default value of 0.5.
This function, it's going to review
a lot of things that we have covered over
the last few weeks for fitting models and
especially for calculating
performance of binary classifier.
Now, in the body, let's
separate the inputs and the output.
Let's make a new DataFrame called
input_df, which is data_df.loc.
I want you to select all rows,
but just with the input column names.copy.
So x_names is a list that stores the column names,
and we're using those to select the column locations.
Next, I want to initialize
the performance metric storage lists.
I will have a train_result and a test_result.
By the end of this week, you'll see we really
only care about the test set performance.
But as a teaching aid,
I will include the training set performance as well.
This function, train_and_test_logistic_with_cv is
actually going to do more
than what you will typically see.
Again, this will be used for teaching.
Next, we must split
the data and iterate over the folds.
For train_id, test_id in cv.split.
CV, that's our stratified k-fold object.
The.split method, when you're
using stratified sampling needs
the input data frame converted to a NumPy array,
and it needs the output converted to a NumPy array.
Because we have stratified cross validation,
we need the inputs,
and we need the output.
If you look, this is
the same syntax that was used in the previous record.
In the previous recording,
when we were splitting,
we needed that input DataFrame converted to a NumPy.
We needed the output series converted to
NumPy in order to give us the training and testing IDs.
This is a for loop,
so we need a colon at the end,
and we now indent further.
By the way, you don't have to manually indent.
Jupyter Notebook takes care of it for you.
But within the body of this for loop,
we are going to subset
the training and test splits within each fold;
train_data gets assigned the result
of data.df.iloc[ train_id,
: ].copy(), test data gets
assigned data_df.iloc[ test_id,: ].copy().
Again, this is the exact same operation
that we did in the previous recording,
though, I'm not creating the index column now.
I'm pulling out the rows from
the entire dataset used for
testing using the.iloc attribute.
Both of these objects are
DataFrames as we saw in the previous recording.
Now that we have the training set,
we can fit the model on
the training data within the current fold.
I'll name this object a_mod, smf.logit.
It has a formula.
It has a dataset, and you fit it.
But now, what is the dataset?
The dataset is not the entire dataset.
The dataset is just the training split.
Since we're using five-fold CV,
this has 80% of the data.
The formula is the formula
that we are providing is the argument.
If you contrast this to what we did last week,
we did not have to do any splitting
last week because we were just
fitting on the entire data set.
We are not doing that now.
Now we are splitting
the data and we will split it multiple times.
You will fit a model within each fold.
Thus, since we have five folds,
we are fitting the model five times.