Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/wU9LI/implementing-cross-validation-with-scikit-learn-logistic-regression

English
Hello, everyone.
As you can see, I already have Jupyter open to this week for the course.
If you don't have Jupyter open, please pause the recording and do so.
Once you're back, I want you to launch a new Jupyter notebook, new Python 3 kernel.
Let's go ahead and change the name of this notebook to week_13_cv_logistic_sklearn.
In this video, we're now going to combine everything from this week,
cross-validation with using scikit-learn's logistic regression in order to train and
assess all the 17 models that we fit earlier, all with statsmodels.
Go ahead and put in our header information, CMPINF 2100 Week 13,
Managing Cross-Validation of Logistic Regression with SKLEARN.
So this is all with scikit-learn.
Let's go ahead and import the modules.
As per our usual convention, I want you to start by
importing in the big four, numpy as np, pandas as pd,
import matplotlib.pyplot as plt, and import seaborn as sns.
Again, we will import in the other modules that we will need and
other functions in a little bit.
Read the data.
Let's return back to the complicated Week 12 binary classification data set.
So we're not going to use the week 11 one, we're going back to week 12.
Read the CSV file, where we navigate back to week_12,
week_12_binary_classification.csv, okay?
We know that this example has five inputs and one categorical or one binary outcome.
The goal, we will use k-fold cross-validation
to identify the best model out of 17
logistic regression models fit in week 12.
So we're going to do the exact same thing as earlier,
but this time, use scikit-learn to not only
generate the folds, but to also fit the models.
To fit the models and score the models.
We will specify the assumptions, Of SKLEARN so
that the logistic regression is consistent with statsmodels.
Okay, now, as with the previous recording,
I'm not going to manually type in all of these formulas.
So again, please go to week 12 classification multiple models.
And I'm just copying these again.
Again, this is to save time and
to guarantee I'm using the exact same formulas.
And just as we saw, right, each element in this list is a character string that
will be used to define a formula, all right?
Now, this is a classification problem, so
we must use stratified cross-validation.
So from sklearrn.model_selection, I want you to import StratifiedKFold.
We will specifically use 5-fold cross-validation,
just as we have done throughout the examples this week.
kf = StratifiedKFold n_splits is 5, shuffle=True.
And just as when we did this with statsmodels,
instead of using 101 for the random state,
let's use 9483156.
If you're wondering why this number, I just typed it in, right?
There's no rhyme or reason for it.
I just typed it in, and I wanted to just be consistent between the two examples.
The get_n_splits method, again, tells us there are five splits, but
we won't actually see the splits until we are using the for loop to generate them.
We will use sklearn to fit and score the models.
So from sklearn.linear_model
import LogisticRegression.
And we need the dmatrices function to
create the feature and output arrays for us.
So from patsy import dmatrices.
All right, we now have everything that we need.
We're now going to define a function in similar spirit as
what we did previously when we were using statsmodels to fit,
predict, and calculate the performance.
But now this function will rely just on scikit-learn.
So it will look similar, but it will be different.
It actually won't have all of the same arguments, okay?
So let's create a new section header, execute cross-validation.
Define a function to manage the cross-validation for
a given model name and formula and dataset.
def train_and_test logistic_with_cv.
Okay, I'll use the same name, but this is using scikit-learn.
The arguments will be mod_name,
a_formula, init_mod, data_df, and cv.
The init_mod is the initialized scikit model object.
Okay, we can assume we have initialized it, but
we have not applied the .fit method.
cv is the CV object.
Notice I don't need to set the threshold here because when we score it,
scikit-learn assumes the threshold of 50%, all right?
Now, in the function, the first thing that we need to do is to create
the feature and output arrays based on the provided formula.
In the previous video, I was calling these y ops mat and x design mat, but
here I'm just going to call it y and X, y for the output, X for the feature array.
That is the result of dmatrices, a_formula, data=data_df.
Next, we will initialize the performance metric storage.
Just as with the previous video, let's also store the training result for
teaching purposes and the testing result,
even though the testing is what we really care about.
Next, split the data and iterate over the folds.
Just as with what we saw previously, we need a for loop,
where we iterate over the train_id and the test_id,
where they are coming from the generator, cv.split.
But because this is stratified, we need to know the input and the output.
So the input is the design matrix or feature array X and the output is y.revel.