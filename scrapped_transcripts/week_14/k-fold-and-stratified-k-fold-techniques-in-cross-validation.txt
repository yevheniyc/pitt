Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/eWnpJ/k-fold-and-stratified-k-fold-techniques-in-cross-validation

English
So kf_a.split input_df.to_numpy.
So I want you to run this.
When you run this line, all it tells
you is kfa is a generator object.
The k fold function therefore
initializes how the data will be split.
But calling the .split method does not return the splits.
The k fold function is similar to the range function.
Remember range, range is a generator.
It only returns values when it needs to.
So if I call range 4, it just says, here's your generator range.
But if you put the range
generator inside a for loop,
now every time through the for
loop, the range function is evaluated.
So calling range four doesn't do anything.
But, using the generator inside a for
loop returns a value that changes.
This is exactly how the dot split method works.
But the dot split method returns two things.
It returns a numpy array holding the row indices for
the training set, and a numpy array
holding the row indices for the test set.
I want you just to work, to run the next cell that I'm about to type in,
because it demonstrates how this generator works.
Again, calling the split method doesn't do anything.
We need to use it within a for
loop, for train_id,
test_id in kf_.split.
And then what are we going to split?
The input data frame converted to numpy.
So this method is returning two things.
These two things change every time through the for loop.
I'm going to use a print statement to show you
that the training set has placeholder d rows
while the test set has placeholder d rows.
Provide the length of train id.
Provide the length of test id.
Well, here actually, you know what we'll do size, since train id.size, testid.size.
Oops, forgot.
There we go.
What this is telling you here is,
each time through, train id has 240 elements.
Test id has 60 elements.
And if you notice, we have printed out 12345 thing.
Five things because the data are getting split five times.
Now why 240 and 60?
Our data set has 300 rows.
240 divided by 300 is 80%.
60 divided by 300 is 20%.
Thus, five fold cross validation
creates 80% of the data for training and
20% of the data for testing.
It repeats this 80 20 trained
test split five times, okay?
So when you say I'm going to do five full cross validation,
what you're really saying is, I'm going to randomly select 80% of the data for
training, and 20% of the data for testing, but you're going to do that five times.
A single train test split with 80% for training and 20% for
testing does that once and only once, and that's not good enough.
You want to do this multiple times.
Okay, great.
But if you are working on a classification problem,
you instead need to use the stratified
cross validation procedure.
Initializing the stratified cross validation
is very similar to the regular cross validation.
I'm going to assign it to kf, stratified k fold.
I want to split it five times.
Shuffle equals true, random state.
So set the random seed, again.
It understands how many times it has to split.
It hasn't done anything yet.
Calling the split, the dot split method for
a stratified procedure requires
providing the input numpy array,
and the the output array.
So this is the main difference.
When you call the split, you have to not only provide the input array,
but you also need to provide the output array.
If you're working in a regression task using regular cross validation,
you only need the inputs, but for classification,
you need stratified, you have to give the input and the output.
Now, why you're doing this, you'll see here when we visualize everything.
As you can see, though, a generator object is returned.
Therefore, the splits are only
accessible within a for loop, okay?
So I want you to run this for train_id,
test_id in kf.split, input_df,
to numpy, df.y to numpy.
And now I want you to print in the body of the for
loop, the training set has placeholder d rows,
while the test set has placeholder d rows.
Train_id.size, test_id.size.