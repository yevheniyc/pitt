Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/ovXUZ/introduction-to-logistic-regression-with-scikit-learn

English
Hello, everyone. As you can see,
I have Jupyter opened within this week for the class.
If you don't have Jupyter opened,
please pause the recording and do so.
Once you're back, I want you to launch
a new Python 3 kernel,
a new Jupyter Notebook.
Let's go ahead and now set the name
of this notebook, week_13_sklearn_logistic.
This will seem like a break compared to the topics of
the previous recordings for
the week because we're going to
learn how to fit logistic
regression models using scikit-learn.
But this video will set
up the last few videos for this week.
So it is an important one because
scikit-learn is organized differently than statsmodels.
Let's go ahead and now put in the header information,
CMPINF 2100, Week 13.
This is an introduction to
fitting logistic regression models using scikit-learn.
You will learn how to use
the array interface for statsmodels as
a preliminary for learning how to
work with sklearn's predictive model functions.
So that's an important corollary here.
You're going to learn the array interface.
I want you to now import modules,
and just as with the previous recordings this week,
we will import some other modules later,
but begin by importing the
big four: import numpy as np,
import pandas as pd,
import matplotlib.pyplot as plt,
and import seaborn as sns.
Now, for this example,
since we're introducing a new interface, if you will,
we will use a simpler example
compared to the Week 12 binary classification example.
Let's go back to the Week 11 example,
which involved a single continuous input
and a binary outcome.
I will assign the result to the df object,
where we read in the CSV file.
But instead of navigating backwards to Week 12,
we're going to navigate backwards to Week 11,
and read in the
week_11_intro_binary_classification.csv five.
Again, there are just two columns,
the input x and the binary outcome y.
Now, we know how to
fit logistic regression models. We know how to do this.
Specifically, we know how to do
this using the formula interface.
The formula interface from statsmodels,
you need to import statsmodels.formula.api as smf.
Fitting the model is really simple.
We assign the result to an object of smf.logit,
where there's a formula,
there's a dataset and you fit the model.
The data is df and the formula is y tilde x in this case.
We're using just a simple linear relationship
between the continuous input
x and the log odds ratio of the binary outcome.
We know how to check the coefficient estimates.
We know how to check the standard errors.
We know how to check the confidence interval.
We therefore know how to check
the p values to examine for statistical significance.
We also know how to predict
a new dataset to support visualization.
We need to make this
dataset and here I'm doing so using a dictionary
within a pd dataframe where my input
x goes from the training set minimum,
and here I'll use a little buffer,
to the training set maximum with
a little buffer with 101 evenly space values.
The visualization dataset is
then a deep copy of that input grid,
and we can therefore make the prediction
by adding in a column pred_probability.
But I'm now going to name
that column pred_probability_statsformula.
So fit_stats_formula.predict input_grid.
The benefit of the formula interface is all we
need is a dataset
containing our inputs to make predictions with,
and this is something we'll return back to here shortly.
It's very easy to make the predictions then,
and then we can visualize them.
So here I'm visualizing the predictions of
the event probability with
respect to the input x as a line chart.
So we could see it's a low probability
of the event when the input is very negative,
and then it's a much higher event probability
when the input is more positive.
Also, we know how to classify
predictions by comparing
the predicted probability to a threshold.
I typically call this the pred_class,
but now I'll add in
the suffix stats formula for reasons you'll see shortly,
and we do this using np.where,
where we compare dfviz pred_probability
to a threshold with the common threshold
being 0.5 or 50%.
If the predicted probability
is greater than the threshold,
return the event, y = 1.
Otherwise, return the non event, y = 0.
We are classifying turning
low probabilities to the non event
and turning higher probabilities to the event.
So this is a quick review and summary
of us working with the formula interface.
I didn't do it here, but we could also have
calculated the accuracy on
the training set if we predicted it.