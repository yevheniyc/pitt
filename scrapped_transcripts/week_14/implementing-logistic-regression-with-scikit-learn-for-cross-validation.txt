Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/0evAV/implementing-logistic-regression-with-scikit-learn-for-cross-validation

English
This is a for loop, so we need a colon.
Now, subset the training and testing features.
X_train is x[train_id],
X_test X[test_id].
In the previous recording,
when we were applying everything with statsmodels,
when we did the splitting,
we were splitting the Pandas DataFrame and we needed
the iloc attribute to get the row indices.
But now, since we're working with NumPy arrays,
we need a single index
because the primary index in NumPy is the row.
Whereas in Pandas, the primary index is the column.
But here, this is why we're giving it
the row to get all columns in a row,
then we subset the training and testing output.
y_train y[train_id], y_test y[test_id].
Now fit the model on the training set.
fit_mod, the initialized model object dot fit,
x_train, y_train.ravel.
Now score the model.
Calculate the performance metric,
the training set score, train_res.append.
The score method is applied as fit_mode.score,
give it the input features and
the known output values, y_train.ravel.
The test set score, test_res.append,
fit_mod.score, X_test, y_test.ravel.
That's it. We don't need to predict.
We don't need the predicted probability.
We don't need to manually convert it to a classification
because.score is doing that force behind the scenes,
and by default, it then calculates the accuracy.
So.score is really saving us a lot of time here.
Then you need to dedent,
get out of the for loop,
and handle the bookkeeping.
Let's store the training set results
where we have the accuracy.
This is from the train_res list.
This is from the set training
and then put in the fold_id,
which again I will just
as I did previously created from the index,
do the same thing for the test sets.
The accuracy comes from test_res,
test_df from_set testing, test_df,
fold_id equals test_df.index plus one.
Then combine the results together,
res_df pd.concat train_df,
test_df,
ignore_index true and then
add information about the model.
I want to know the model name,
I want to know the model formula,
which is the a_formula,
and res_df, the number of coefficients.
Originally, when we did this,
we could get the number of coefficients from
the length of our statsmodels params attribute,
but we no longer have the statsmodels resolved.
But that's okay because what we
do have are one of two things.
We could either use the feature array itself to
figure out the number of
coefficients because the number of
columns here equals the number of coefficients.
Alternatively,
if we have statsmodels
fit the intercept as a regular coefficient,
then the intercept is included in the coef attribute.
I can convert it to a 1d array and get it size.
That's what I'll do here, and then return everything.
We now have our function that's going
to generate the features from the formula,
iterate over all of the splits,
train and test in each fold,
and then manage the bookkeeping.
Let's initialize the sklearn logistic regression model
to be consistent with statsmodels.
Sk_min_loss LogisticRegression, the penalty is none,
the solver is lbfgs,
fit_intercept is false,
and then lastly let's set max_iter.
This is the number of iterations in the optimizer.
Let's make this really big, 25,001.
These other three we
talked about in the previous recording,
and this is the new one, but it's just
making sure we use a huge number of iterations.
Let's test things out on one model.
Let's use formula list.
Let's use the third element,
the model with all inputs,
linear additive features.
Train and test.
I'm going to name it model 3, formula_list 3,
the init_mod, sk_min_loss,
the data_df is df,
the cv object is kf.
There we go. We have now
executed the training and testing
on our five folds scoring the model in each fold.
Let's now iterate over all models.
We previously saw that statsmodels
crashed with the last model,
but let's see what happens here with sklearn.
Initialize the result as an empty list,
and then for m in range len formula_list,
we'll print out a string to help us out.
Formula ID placeholder d,
where the place holder is m, results_list.append,
train and test logistic cv, m,
formula_list m, sk_min_loss,
data_df is df, cv equals kf.
Notice it ran.
It didn't display that it finished
the optimization because scikit-learn does not do that.
Also notice we got a warning.
It has to do with the last model,
but we have all models here.
Warnings were provided, but nothing crashed.
Well, there's a caveat.
We will discuss what happened next week here.
We will wrap up the semester by
talking about actually what's happening.