Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/VJLOd/handling-errors-with-try-except-a-strategy-for-model-fitting

English
How can we overcome this error?
Let's use a very simple strategy.
Let's use a try/except procedure.
This strategy involves trying something and then if
an error or exception is raised, print a message.
That's the main thing that we're going to use this for.
So we're going to use essentially the same code.
But we're going to modify it
slightly to handle the error.
Results_list empty.
For n in range(len(formula_list)).
Use the same print statement,
print formula ID placeholder d,
where the placeholder is m. But now, here's the syntax.
Try colon, you see how indents,
just put a comment for now,
"Enter", "Control left square
bracket" to de-indent, except, colon.
Put in a comment for now.
Now, what are we trying?
We are trying to append to results_list,
the result of train_and_test_logistic_cv,
where the name is m.
The formula is the mth element from formula_list.
The data is df,
x_names is input_names,
y_name is output_name, cv is kf.
So the cv object is
kf and we'll use the default threshold,
but now, the exception,
this is what happens if there is an error.
Let's just print and I'll use exclamation points,
so it's obvious what's getting printed.
Print, formula ID placeholder could not fit,
and the placeholder is m. Now running.
Everything starts out the same.
If we scroll down, once we reach that warning message,
instead of an error message ultimately being shown,
we're getting our formula ID 16 could not fit.
If we check the length of results_list,
you can see its length is 16,
even though the length of formula_list is 17.
This means, our last formula,
which could fit on the entire dataset
does not work if we split the data.
This is our first hint,
maybe that really complex model from last week,
the model that had 81 coefficients,
which was doing the best on the training set alone,
maybe there's something goofy going on with that model.
Maybe that model is not reliable.
Let's combine the results for all models that did work.
I'll name this cv_results,
pd.concat results_list, ignore_index true.
Cv_results now stores the accuracy on
the training set and test
set within each fold for each model.
Each model is trained five times and tested five times.
So in our current setup,
that's why each model has 10 rows.
We can also visualize that as a dodged bar chart.
Model_name hue from_set kind = count, plt = show.
Each model is trained five
times and each model is tested five times.
Let's look at the accuracy values
for each model in each fold.
Sns.catplot data = cv_results,
x model_name, y accuracy.
Now I want to distinguish in the training and test sets.
I want to distinguish whether we're working with
the training or the test set. So I'm using hue.
Now, this is the default catplot,
which is known as a strip plot.
But each marker here is a row in the dataframe.
So do you see this blue marker
on the far right hand side?
This is the accuracy for model 15 in one
of the folds training set. See this other marker?
This is the accuracy for one of the folds for model 15,
but a different fold,
still for the training set.
Visually, what we're seeing here is model 15,
its training performance is
completely separated from its testing performance.
The training performance is between 80 and 85% accuracy,
but the testing performance is around 62% accuracy.
Now, this figure, it is difficult to look at.
Instead, we are typically
concerned with the average performance.
Rather than looking at individual fold results,
but I wanted to visualize that to you here.
First we are concerned with the average performance.