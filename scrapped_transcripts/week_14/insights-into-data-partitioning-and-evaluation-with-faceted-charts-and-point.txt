Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/FvFUS/insights-into-data-partitioning-and-evaluation-with-faceted-charts-and-point

English
Let's go back up to the picture now.
When the zeroth row is held out,
this fold, fold_id 2,
does not include row 0 in the training set.
The coefficients will be
estimated without that observation.
We are using that observation as
if it's new data in fold 2.
However, in fold 3,
for example, the zeroth row is not held out.
That's because we are testing on other rows.
Let's take a look at fold 3. test_splits_df.loc,
test_splits_df.fold_id equals equals three,
rowid 2. train_splits_df.loc,
train_splits_df.fold_id equals equals three.
0, 1. rowid 2 is held out of fold training set.
This means cross-validation creates
different training sets for you.
The training sets are randomly created
by subsetting the rows of the entire dataset.
Five-fold cross-validation uses 80%
of the data for training.
Thus, most of the training data
are the same across the folds.
However, 5-fold CV uses 20% of the data for testing,
and the 20% for testing is different in each fold.
That's because we are forcing
each data point to be held out once and only once.
You are testing each data point once.
The test set in fold 2
is different from the test set in fold 4.
Let's visualize these ideas.
Again, you don't have to do this.
This is just to reinforce what's going on,
but I'm going to add in a column
that identifies if it's the training set
or the testing set and then combine everything together.
Now my train splits and
my test splits will be put into a single DataFrame.
As we have seen now multiple times,
each fold is using 80% of the data for training,
20% of the data for testing,
meaning each fold has
the same number of
training points and each fold
has the same number of test points,
but the test points are
different in each fold as we've seen.
Now, stratified cross-validation makes sure
the event proportion is
roughly the same across the folds.
Regular cross-validation does not.
That's why it's so critical that you use
stratified when you are
working with a binary classification problem.
So sns.catplot data equals all_folds.
I want to confirm this.
Kind equals count,
row equals from_set, column equals fold_id.
I'm creating a faceted bar chart.
The training sets are shown on the top row.
The testing set sets are shown on the bottom row.
The columns are telling you the folds.
In fold 1,
we are visualizing the number
of non-events and the number of events.
In the training set,
the bottom row is showing us
the number of non-events and events.
In the test set, the relative heights
between the non-event and
event are the same across the folds,
whether you're in training or testing,
and that's easier to see for training than test.
If you take your catplot,
you set your facets
but then force share y equal to false.
Now, the y-axis is allowed to be
different across all the facets.
I'm doing this just to highlight that the test set,
it has basically the same proportion
of events as the training set,
and that's true for every single fold.
We can quantify that effect, though,
because value counts apply to the output.
If you normalize it, you get the proportion.
This is the same thing as applying
the mean method because
our binary outcome is encoded as 0, 1.
We can, therefore,
visualize the proportion of
the event by using a point plot.
Now, I'll use the column facets for
the training versus test set.
In my point plot,
the x-axis is the fold_id,
the y axis is the binary outcome.
We're looking here at the proportion of events.
You can see it's very,
very close across the folds in the training set,
and it's really, really close
across the folds in the test set. It's not perfect.
It's doing it the best it can.
Regular cross-validation, there's no guarantee.
You might have a fold that has
much lower proportion of event
and a fold that has a much higher proportion of event.
Stratified cross-validation is random,
but it's trying to guarantee
the event proportions are
very close to the same across all the folds.