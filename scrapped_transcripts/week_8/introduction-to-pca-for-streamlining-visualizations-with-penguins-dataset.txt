Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/mj3HC/introduction-to-pca-for-streamlining-visualizations-with-penguins-dataset

English
Hello everyone.
In this video, we're going to introduce an approach to help streamline some
of your visualizations.
As you can see, I already have Jupyter opened up.
If you don't, please pause the recording and do so.
Then when you come back, launch a new Jupyter notebook.
Let's name this notebook, week_08_pca_intro.
Now put in the header information,
CMPINF 2100 Week 08,
introduction to PCA in order to
support cluster analysis,
let's import our modules again.
We need the big four import numpy as np,
import pandas as pd,
import matplotlib.pyplet as plt,
and import seaborn as sns.
Let's read in some data,
start with the penguins data set, again.
Penguins it's the result of
sns.load_dataset(`penguins`), penguins info.
All right, why this thing called PCA?
The Penguins data has 4 numeric columns.
We know that we have explored this data set multiple times now.
We've examined the marginals, we've examined the relationships.
We've examined conditional distributions,
we've looked at the pairs plot multiple times.
We've also seen there is a clear relationship or
correlation structure between several of the numeric columns.
Let's visualize that specifically
with a correlation plot via a heat map.
Let's apply the core method to just the numeric columns again,
whenever you make a correlation plot, you must set the bounds.
Vmin-1, vmax1, center0,
cmap is coolwarm, and then we can
annotate set the font size ax=ax and
we've looked at this figure before.
Two of the variables are very correlated, lots of linear relationship,
which we can see here in the scatter plots.
Others have different correlation structures.
But why PCA?
PCA tries to exploit correlation between variables.
This is beneficial because maybe we do not actually
need to look at all pairs of scatter plots.
If we can exploit the relationship between variables,
maybe we can create literally new
variables that capture the impact or
influence of all variables.
Then, instead of having to explore a large number of figures,
we can focus on the relationship between
several newly created variables.
That's the goal of PCA.
PCA is saying if you have highly related variables, maybe you don't
need to look at both because they each are representing nearly the same thing.
Can you then create variables that account for the relationships or
anti relationships between other pairs of variables?
Just how PCA works is something that will
be discussed in more detail in CMPINF 2120.
We will also revisit PCA later in the semester
in this course, CMPINF 2100.
But for now, let's just see how to use PCA to support visualization.