Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/hyQ4Z/reshaping-the-diamonds-dataset-for-effective-data-visualization

English
Lastly, the Sonar dataset.
Again, to get the data, here is the URL, you copy it, paste it in.
To read in the data we need pd.read_csv using the sonar_url link.
But as mentioned in the previous video, you cannot specify or
there is no header row and so you need header equals none.
Now what I like about this example is this data set.
Again, the number of rows isn't overly huge,
but there are 61 columns.
If you would even just apply the info method.
It's hard to read because there are just so many variables in this data set.
We need methods that are going to help us find patterns
across all of these columns so we can better and
more informatively visualize and explore the data.
So again, I wanted to motivate why we need these unsupervised methods.
Cases where we have potentially an enormous number of rows and
large numbers of columns, where it becomes
difficult to really manage all of the columns.
But what I want to conclude on this video with is just
because we're going to be discussing clustering in PCA,
it's very important to do not forget about reshaping.
Reshaping wide to long format will
help you explore many columns.
I want to illustrate this by first showing you how to reshape diamonds.
Let's reshape the diamonds data frame from wide to long format.
We will gather or stack all numeric columns on top of each other.
The non numeric columns will
not be gathered or stacked up.
So the first task we need to do is we need to
create the set of names for the numeric columns.
A very easy way to do that is to use the select_dtypes
method to select all number columns,
pull out the columns attribute and force it to a list.
Now we have 1,2,3,4,5,6,7,
seven column names, and if we go back to diamonds,
there are seven numeric columns.
Next we need the category names.
Again, apply the select_dtypes method, but this time to category rather than number,
pull out the columns attribute and force it to a list.
Now we have the three categorical columns or category columns.
Reshape from wide to long to reshape from wide to long,
as I mentioned last week, I first like to reset the index.
That way I create a column that corresponds to the unique row index,
but I like to rename that column from index to row id.
Now I know this is the id for
the row in the original wide format data set, and now I will melt.
I will stretch it from its current format to long
format where the original wide format rows are uniquely
defined by row id plus the category names.
The values to stack on top of each other are the numeric columns.
We now have over 370,000 rows, but the data have not changed.
We have just reorganized it so we can see,
here's the 0th row for the caret variable.
Here was its value, and
here are the values of the three non numeric variables associated with it.
Let's assign this result to diamonds lf,
again, we have converted from having 10 columns to just 6.
We can now associate the variable
column within the long format data with the call
argument to create column facets.
So let's make histograms contained within facets for all numeric columns.
Sns.displot, d-i-s_p-l-o-t,
(data=diamonds_lf, x=) the value of
the numeric column will be associated with the x axis.
The column facet will be associated with the variable column because that is
what's containing, here let me actually make this more formal.
Let's apply value counts to the variable column.
Contained inside the variable column are the names of all of
the original numeric variables.
So that's why that column is associated with the column facets.
I want to wrap such that I have just three columns per row and
I want to create histograms, so kind=hist.
But as discussed last week,
I want to make sure I do not share the x and
the y axes and I need to set common_bins to False.
This way each facet can contain a completely separate histogram.