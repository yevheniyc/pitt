Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/YkdiO/analyzing-event-probabilities-and-input-bins

English
Let's now focus on the right hand side of
this figure where the input is greater than 1.
In this example, these values of the input
are associated with very high event probabilities.
All of the predicted probabilities here are above 50%.
As you can see, most of them are above 75%.
Well, that's like me telling you I'm going to flip a coin 100 times and
there's a 75% chance of heads.
You should expect that we will see many more heads than tails
because the probability of heads is much higher than tails.
Well, look at the number of events y=1
versus the number of non events y=0.
When the predicted probability is very high,
we will see more events than non events.
Lastly, now look in the middle interval where
the predicted probability is between 25 and 75%.
And as you can see, it's crossing that 50% threshold here.
Well, if the probability is 50% and
I told you I'm going to flip the coin 100 times,
it's a fair coin, quote unquote,
you would expect we would have an even mixing or
similar counts between heads and tails.
I wanted to show this to you to highlight the relationship between the counts.
What we observe for the non event and
event compared to probabilities.
The probabilities are laying out what we expect to see.
The observations of the output event or
non event are those binary or
discretized versions of those probabilities.
Low probabilities will have more non events than events,
high probabilities will have more events than non events, and
probabilities near 50% will have a roughly even mixing of events and non events.
Let's reinforce the idea of
probability versus event and
non event one more time, but
using the training set.
So I'm going to make a copy of my training set called DF copy.
And let's convert the continuous input
into a non numeric or categorical variable.
However, we will not directly make all
unique values of the input categories.
Instead, we will discretize or
bin the input into cut intervals.
So instead of having one category for each unique value of the input,
I'm going to discretize my input into three buckets, three bins.
One bin with the input less than -1,
another bin where the input is greater than one, and
a middle bin where the input is between -1 and 1.
So it's going to follow this picture.
The pd.cut function will cut
a continuous variable into intervals.
So this is another way of converting a numerical into a non numeric.
But instead of giving you one category for
each unique value it will bin the values into intervals,
and that's even why I wanted to use just three.
So it'd be easy to visualize basically all of
the observations of the input here that I'm pointing to
will be converted into one category, the less than -1 bin.
Likewise, all of the values of the input greater than one
will be converted into a category, the greater than one bin.
So let's, let's see how to do this.
df_copy add a new column.
So give me in here, let's confirm that this, let's confirm what the columns are.
df copy.head it's just x and y.
But now it looks like I'm going to access a new column named x_bin,
which does not exist right now in this data frame.
However, I'm going to assign something to it.
I will assign the result of Ppd.cut.
The zero argument to pd.cut is the series I want to cut.
So I'm accessing the x column from df.
The next argument is known as the breakpoints.
What are the points, the values that define the bins.
Or what are the values that define the bounds of the interval?
So here I'm going to define that interval
as the minimum value of x up to -1
then one up to the maximum value of x.
Lastly, there's an argument include lowest I
want to include the lowest value in the lowest bin, and
then I want the bins ordered from lowest to highest.
So now as you can see,
we ran this line of code and it worked.
If you check the .info method,
the .info method says there's now an x bin column, which is a category.
If we check the number of unique,
there are three unique values of this variable
of this column we have four breakpoints.
Min to x= -1,
-1 to 1, 1 to the max.
So three intervals are defined
by four breakpoints.
If we use value counts,
You can see the names of these categories.
They look a little strange, but what they're
saying is this bin goes from -2.06 to -1,
this other bin goes from -1 to 1, and the last bin 1 to 2.439.
And we can make a bar chart.
df copy x =x bin kind equals count.
The way this binning was done, the middle bin has the largest interval,
you know, has an interval width of two the others are negative.
It has a width of one and one and a half, roughly.
So we have more observations in the middle interval.
But why did I want to do this?
Let's group and summarize within each input bin or
input bin to calculate the number of events and
the proportion of events.
df _copy grouped by group by x bin.
Then aggregate and I'm going to calculate three things,
the number of rows, the number of events,
and the proportion of events.
Then I will reset the index.
That way a regular data frame is returned.
So now the number of rows.
I want to take the y column and get the size,
the total number of rows for that variable.
Now the num events well, the output y is 0 or 1.
The number of events is equal to the sum of the binary outcomes.
The proportion of the events is the sum
divided by the length or the mean.
Because the output, the binary outcome y is 0 or 1.