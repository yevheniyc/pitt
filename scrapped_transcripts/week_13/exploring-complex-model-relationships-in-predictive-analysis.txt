Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/sTkMQ/exploring-complex-model-relationships-in-predictive-analysis

English
But input grid has over 2,700 rows,
x1, 101 unique values,
x2 has nine, x5 has three unique values.
The input grid, x5 value counts.
All three values are the
same as the three unique values
as x in the training data.
But as you can see, the distribution
of them is different.
They're even because this grid is literally an even grid.
For example, if we want to actually look
at what this grid is effectively doing,
we have the input grid,
x = x1,
y = x2, column = x5.
We're creating a grid for different values of x1,
x2, and x5,
and x3 and x4 are constants.
Now, why did I want to do this?
Remember, we fit a few models earlier.
We had model__bb,
it had linear additive features.
We can create a dfviz.
Let's make a deep copy of the input grid, dfviz,
the predicted probability for
the bb model, mod_bb.predict_input_grid.
Mod_bb was the same formula as,
here we go, Model 3.
This model had seven coefficients.
It has an accuracy on the training set equal
to the constant event probability.
This model is not doing any
better on the training data
as assuming there's no relationship.
Let's see that. Sns.relplot(data = dfviz,
x = x1,
y = pred_probability_bb,
hue equals, I want to color by x5),
and now the columns will be x2.
The kind is line estimator of
none units x5,
because that's the color, col_wrap3.
I want to have three columns per facet.
When x2 increases,
the predicted probability is going down.
Mod_bb.params, x2 is a negative slope.
X2 was a statistically significant feature.
X1, we saw was
a statistically significant positive slope.
The probability of the event is
increasing as x1 is increasing.
But let's now fit
our complex model directly
so we can make predictions with it.
The formula, oops.
There we go. This is the last element in the list.
The most complex formula.
So we'll name this one mod_complex = smf.logit,
there's a formula,
there's a data set, dot fit.
The data is df,
because we're not in the function.
The formula is formula_list,
the length of that list minus 1,
because remember this is excluded.
Mod_complex.params.
There are so many coefficients here. There are 81.
The display doesn't actually even show them all.
If you want to see all of them,
we can convert it to NumPy,
and now you can see all of
the slopes that just got estimated.
In dfviz, let's now have
a predicted probability complex,
which is mod_complex.predict on the input grid.
Now let's visualize dfviz,
x = x1,
y = pred_probability_complex,
hue = x5,
col = x2,
kind = line,
estimator = none,
units = x5, cal_wrap = 3.
This model is so complex,
it's capable of having all of
these crazy looking relationships.
Look at when x5 is a,
and x2 is this value,
the probability of the event is the green line.
It starts at 0.
It increases rapidly.
I flat lines near 1,
and then it decreases rapidly again as x1 is changing.
However, depending on the value of
x2, that relationship,
that behavior with respect to x1 and x5(a) will change.
Look at the green curve
across the different facets, the subplots,
until x2 becomes so positive,
the predicted probability is always zero,
with respect to x1 and x5.
The reason why I wanted to show you this is,
this model is considered to be the
best according to all of our training set metrics.
It has the most number of features,
it has the most number of unknowns,
it's capable of creating all
of these crazy relationships,
and our performance metrics say it's the best.
Next week, we're going to
finally learn why this matters,
and how you actually
identify the best model because, spoilers,
this is not the best model,
even though the training metrics say it is.