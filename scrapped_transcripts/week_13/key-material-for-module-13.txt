Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/4hcAe/key-material-for-module-13

English
Hello, everyone. Welcome to
the 12th week of the semester.
This week is dedicated
to working with logistic regression.
Last week, you learned that
logistic regression is intended
for binary classification problems.
But you saw that
logistic regression models predict event probabilities.
Meaning the models do not
actually classify event or non event.
This week begins by you learning how we
go from predicting probabilities
to actually making classifications.
Once you have the classifications,
then you can calculate the performance metrics.
You can directly compare classifications
from the model to observed binary outcomes.
These performance metrics are ultimately
assessing if the classification is correct or not.
But there are multiple ways of
defining how that classification is correct.
You will specifically learn
four such metrics, the accuracy,
the sensitivity, the specificity,
and the FPR or false positive rate.
You will learn that these four metrics are all
derived from a graphical tool
known as the confusion matrix.
The confusion matrix sounds like something brand new,
but you'll see in the examples,
this is really just a heat map that shows
the counts for the combinations
between two categorical variables.
You actually already know how to make this thing.
The performance metrics are just
manipulations of those counts.
Lastly, you'll learn how these four metrics relate
to another graphical tool known as the ROC curve,
and you'll learn why it's such an important and
useful metric in classification.
Now, all of the examples,
they first show you how to manually calculate the metric.
This is done so that you can see how the metric is
calculated as well as
important comments on their interpretations.
But ultimately, you will be allowed to
use streamlined functions from SKLEARN,
which calculate the metrics in single lines of code.
I first show you how to do it.
But then I relate how those steps
are encapsulated in single function calls.
That way, you don't have to manually go
through and do all those calculations yourself.
Lastly, you will bring together
all of these ideas of fitting logistic regression,
calculating performance, and ultimately making
predictions in a realistic example.
The very last thing for this week shows you how to
fit and assess many different logistic regression models.
You will fit 17 different models,
and these models make use of concepts from last week.
Additive features, linear additive features,
interaction features, how you can add
a categorical input or interact a categorical input,
how you can derive non linear features from your inputs.
All of these different models are
fit on the same training dataset,
and you will learn that
the training performance gets better or
improves as you have
more and more unknown coefficients
that must be estimated.
Or effectively simply adding
more and more features will
make your models appear to get better.
That's where we conclude this week.
Next week, you will finally learn how
to actually identify the best model.
This week is all about how you calculate the performance,
how you can derive features and
examine their performance on the training data.
But next week, you will actually be
able to identify which model is the best.