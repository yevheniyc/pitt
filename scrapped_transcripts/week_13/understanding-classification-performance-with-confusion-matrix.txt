Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/mjCab/understanding-classification-performance-with-confusion-matrix

English
Hello, everyone. As you can see,
I have Jupyter opened to this week for the class.
If you don't have Jupyter opened,
please pause the recording
and do so and want you're back,
I want you to launch a new Jupyter notebook,
a Python 3 Kernel.
Let's name this notebook
Week 12, classification, confusion.
This name confusion is very
important in classification settings.
What you will learn in this video
is how we can extend the idea to
accuracy from accuracy to
know how a model is right and wrong.
This style of metric is organized into something known as
the confusion matrix so
that's why this notebook is named this way.
Rename it. Now, let's put in the header information.
CMPINF 2100 Week 12,
measuring classification performance, confusion matrix.
Let's go ahead and import
the modules that we've used in the previous recordings.
You need the big four. Import numpy is np.
Import Pandas is pd.
Import matplotlib.pyplot as plt.
Import seaborn as sns and as with
the previous recordings, import statsmodels.formula.api.
Now, this recording is going to repeat
many of the actions from the previous recording,
and that's okay because it will serve as
a review of the fundamental approaches
required to fitting and
training and assessing logistic regression models.
Let's read in the data.
Again, read the data from last week,
assign the data to the Df object,
pd.read_csv, for the file path,
navigate backwards one directory,
then choose Week 11,
then the file Week 11,
intro to binary classification.csv.
Here's our dataset.
Want you to fit the model,
fit_glm it's assigned smf.logit
where there's a formula.
Actually, I had made a mistake. Look at that.
As you saw when I was trying to
tap complete nothing was appearing.
Let's go back up. Import statsmodels.formula.api as smf.
Now, because I made this mistake,
I'm going to take the kernel restart and clear output.
Now everything is just getting restarted.
That's all right. You have to do that sometimes.
Now I will re run from the beginning,
importing my modules,
reloading the data, very good.
Now let's fit the model fit_glm equals smf.logit.
Now you can see when I hit tab,
I get tab complete because I now
have the alias that I want
for the stats models formula API.
There's a formula. There's a data set and we must fit.
Data equals df formula equals y Tilde x.
Rate, it fit successfully.
Now, predict the training set
and as discussed in the previous video,
I like to make a hard copy.
Logistic regression
predicts the probability of the event.
Let's make a new column,
pred probability fit_glm.predict.
The training set, and now
classify the training set, df_copy pred_class.
Remember, we need to specify
a threshold to compare the predicted probability too,
np.where gets assigned the result
of df_copy.pred_probability.
If it's greater than the threshold, return the event.
If it's less than the threshold,
return the non event,
and I'm continuing to use
the default threshold of 50 percent.
Now, we know how to calculate the accuracy.
The accuracy is the proportion
of correct classifications,
np.mean applied to
df_copy.y equals equals df_copy.pred_class.
Our model has an accuracy of
roughly 68 percent or let's just call it 2/3.
But accuracy does not tell us how the model was
right and accuracy does
not tell us how the model was wrong.
It's simply telling you it was
correct at this proportion.
Many times we need more information or
details about how the classifications
were right or wrong.
We need to examine the errors.
The errors in a binary classification problem are
typically organized in a graphical tool
known as the confusion matrix.
Let's go ahead and now talk about the confusion matrix.