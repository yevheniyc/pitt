Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/tWRGB/examining-the-categorical-variables-of-the-datasets

English
Hello everyone, in this video, we're going to learn about creating
bar charts to visualize counts of categorical variables.
As you can see, I already have Jupyter opened up to this week's directory.
If you don't have it open, please pause the recording once you do, come back and
launch a new Jupyter Notebook, going to name this notebook.
Week 6, pandas bar charts,
put in the header information comp with 2100 week 06,
creating bar charts with pandas.
This week we have seen how to use
Matplotlib to organize our plots.
We saw the difference between the figure and axis objects.
Those organizational approaches are really important.
But I will very rarely create plots in Matplotlib directly.
Instead, statistics plots such as the bar
chart will be created using pandas or seaborn.
This recording is all about working with pandas.
So this notebook shows how to use pandas.
Let's import our modules.
As with the previous weeks, import numpy as np, import pandas as pd.
Now, even though we will use pandas to make the plots,
pandas is actually using matplotlib to organize everything.
Thus we must also import matplotlib.piplot as plt.
So you need numpy pandas and matplotlib.pyplot for this notebook.
Now that we have the modules, let's read data.
We will use the gap minder dataset and
the penguins datasets for this notebook.
I want to define the URL as a string, just as in the previous recording.
So if you don't have canvas opened, please pause the video.
Go to canvas.
Go to the module 6 data for
this week where on that page there is a link to the pandas for everyone.
GitHub to the raw page.
Here is the link to the raw tab separated file.
Copy it and paste it in.
Then read into pandas that data set where again
the separator is changed to the tab separated file.
If you have read in the data correctly, you will see that the dot
info method tells you there are over 1,700 rows for the six columns.
The penguins data set penguins sns, oops, sorry, I'm actually, I forgot about it.
Go back up.
I forgot to import seabourn as sns there we go.
So we have the three followed by seaborne import seaborne as sns,
then go down penguins equals sns.load dataset.
Type penguins as a string.
Again, if it worked correctly,
the dot info method should tell you there are 344 rows for seven columns.
Let's start with Gapminder.
The previous recording stated which variables
are categorical versus continuous and
the number of unique values per po.
As a quick reminder, gap df, d types and gap df and unique.
In the previous recording we mentioned country
continent are definitely non numeric and
we saw that year has just 12 unique values and so
we could consider it as like a categorical when we explore the data.
When you explore data, you have to go through every single variable.
I personally like to start with the categoricals with
the fewest number of unique values.
So let's visualize the counts for continent.
But before doing that,
we already know how to count the number of rows
per category of a categorical variable.
My favorite pandas function apply the value
the value counts method to a column.
I'm starting with continent because it is string.
It's object data type, which is five categories.
Value counts shows up each of those five unique values,
and the count the number of rows associated with each of those values.
Let's confirm this is working.
Confirm value counts is actually working.
And when you're visually exploring a real data set, say in your projects,
you don't have to do this confirmation, but it's useful for right now.
Gap df.loc we will identify or select or
filter rows where continent is equal to.
How about Oceania?
According to value counts, there are 24 rows.
If we apply the shape, or if we extract the shape attribute out of
this filter data set, you can see there are only 24 rows.
So there are 24 entries where continent is Oceania.
Let's now examine where gap df continent is equal to Asia.
396 rows.
Again, 396 rows.
If we scroll up, by the way to the info,
we can see there are no missings and
we can confirm that gap df is na.sum there are no missing.
So we, we don't have to worry anything about the missing values here.