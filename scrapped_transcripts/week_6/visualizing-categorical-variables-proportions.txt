Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/SDJqS/visualizing-categorical-variables-proportions

English
Sometimes, though, you want to show
the proportion rather than the count directly.
We know how to show the proportion from value_counts.
You identify the column,
you apply value_counts,
and then you set normalize equal to true.
Now, you get the proportion or fraction per unique value.
Value_counts with Pandas makes
it very easy to show a proportional bar chart.
A proportional bar chart is created by applying
the plot method to the normalized value_counts result.
So the actual set of code is
very similar except for one change.
First, define the figure and axis objects,
plt.subplots, figsize,
here we'll use 12, 6 again.
Take the data set,
identify the particular column,
apply the count value_counts,
but now normalize=True, plot,
method, kind=barh, ax=ax, plt.show.
At first glance, it looks to be the same,
but now look at the value on the horizontal axis.
We no longer have values in the hundreds,
we just have small decimal points.
We get over 35% of the observations are for Africa,
a very small set of
percent of the data come from Oceania.
You must visualize the bar chart
for every single categorical variable.
This may take a while,
that's okay to do.
Never, never, never skip
out or try and skip over variables,
you'll end up hurting yourselves.
I know this seems like it will be tedious,
but you must explore every variable.
When I'm exploring a dataset,
I may make 10,000 figures,
that is completely okay.
I may only show to my clients or my supervisor,
my boss's boss's boss,
I may only show a handful of critical figures,
but I have personally made
thousands of figures when I explore a dataset.
You are not doing it
incorrectly if you make a lot of figures,
you are doing things wrong if you try and work too
quickly and make a small number
of figures and you miss something.
What I'm trying to get at here is,
I just made the bar chart for one and
only one of the variables in gap_df.
We need to go back and now remind ourselves,
in addition to continent, we also have country.
We know, if I scroll back up,
country has 142 categories.
This is going to be a challenging graph to look at.
That's okay, we're going to make it anyway.
Let's now examine the other categorical variable country.
It starts the same way,
fig, ax = plt.subplots.
Let's begin with the default arguments,
gap_df.country.value_counts().plot(kind=bar, ax=ax),
plt.show. Now, this figure
is next to impossible to look at.
I can't read anything on the horizontal axis,
so let's go ahead and change the fig size.
Let's make it rather wide,
18 and not very tall, four.
It's still difficult to
read each individual country name.
But this one figure is actually
showing us something incredibly important,
even if it's tough to see the individual categories.
Because don't forget about the other axis,
don't forget about we are showing,
in our bar chart,
the count per category or the number of rows.
This one chart is telling us it
looks like every category has the same number of rows,
and that is equal to 12.
Well, if we would have instead just
applied value_counts, yes,
we would get a printout of 12,
but because there are 142 unique values,
there's a whole lot
of countries skipped by this printout.
We would have a very long table to read through.
This one visualization gives
us a hint that, you know what?
They may all have the same number of rows.
Now, we can quantify and
demonstrate if that is the case by actually
applying value_counts two consecutive times.
This now tells us a count of 12 occurred 142 times,
meaning every single unique value had exactly 12 rows.
Would you know to follow
this approach when you're exploring
the data to try nesting
or chaining together value_counts twice?
Maybe not. But the hint that you should
consider doing it is made by
this bar chart because it
seems like they all have 12 rows.
Then we can confirm it with the hard values.