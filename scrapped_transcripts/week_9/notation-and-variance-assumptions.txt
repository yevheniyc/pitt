Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/tY81q/notation-and-variance-assumptions

English
Now, to save time, I'm not going to type these equations in this example.
All of the equations are available.
In this presentation, I demonstrate how to write this random
aspect of the linear model, and I use formal statistics terms.
Do you see this vertical bar?
That means given the y variable, the output,
given the input, the intercept, the slope, and
this other thing we'll talk about in a second is distributed as.
That's what tilde means.
Normally, there is a gaussian distribution that is
relaying the fact that our outputs are all random or stochastic.
They are normally distributed.
And we know that all Gaussians have to have a mean or
NumPy terms, a location.
The mean of the output in the linear model
is the formula that we used for our trend.
This is also referred to as the deterministic portion.
And what deterministic means is if you plug into your
calculator an intercept of 0, a slope of 1, and
an input of 1, you will always get the mean of 1.
No matter how many times you plug in those terms,
every time you enter in 0 plus 1 times 1, you will get 1.
There is no aspect of randomness.
The trend is literally how does the input influence your average output?
This is one of the key understandings of what's going on in linear regression.
We are not actually trying to predict an individual output.
We are instead trying to predict its average behavior.
But the individual observations that we collect
have variability around the average.
They are normally distributed with standard deviation sigma.
This standard deviation is constant and never changes.
So let's now see the impact of this assumption of a gaussian
distribution centered on the trend with constant standard deviation.
Let's demonstrate these facts with code.
We will simulate random outputs around the trend.
We therefore need to set the seed to control or
to ensure reproducibility.
Let's initialize our random number generator.
Rg equals NP.random.defaultRng with a seed of 2100.
Our previous figure used 101 values of x.
But let's create a smaller data set to help visualize randomness.
This data set will have nine unique values of the input
between negative three and positive three.
Df equals Pd dataframe.
Now use a dictionary with a key x and
the value NP linspace negative 3 to 3 Num equals 9.
6 rows, 1 column calculate the trend.
The trend has nothing to do with randomness.
It is always the intercept plus the slope times the input.
The randomness comes in due to
the output around the trend.
We need to specify the value of the standard deviation sigma for
our Gaussian distribution, and
I'm choosing that standard deviation to be 1.25.
We must set the standard deviation in our gaussian likelihood.
I'm going to use that term again, likelihood.
I'm choosing this value.
I could have made it smaller, I could have made it bigger, but I want to use 1.25.
We will learn how to interpret this value later on.
For now, it will control the randomness around the average.
Let's now generate our outputs and assign them to a new column y.
We need the random number generator rg.normal,
where the location is the trend, and
I will convert it to a NumPy array just in case.