Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/GtmHc/elastic-net-penalty-for-optimal-model-performance

English
Now, in a previous recording, I showed you how to fit an elastic net penalty.
You might have been wondering, why would we want to blend or
mix the ridge and Lasso penalties?
After all, Lasso literally turns things off.
The reason is because Lasso does not know what
to do when features are highly correlated.
It's not sure which features should be turned off
if the features literally represent the same thing.
Therefore, Lasso may struggle in
the presence of highly correlated features.
But ridge can manage highly correlated
features because ridge does
not truly remove any features.
Therefore, if tuning elasticnet
produces a ridge model,
that tells you that the feature
correlation is impacting things.
This is one of my favorite reasons for using the elastic net penalty.
Because if you're working on a problem and you see the inputs are correlated and
you're not sure if that correlation is going to cause problems, and
there are too many inputs for you to manually pick out which ones to focus on.
Tune an elastic net model.
If the tuning produces a ridge model,
the L1 ratio goes to 0 and thus you have ridge.
That is your clue.
The input correlation is causing problems.
However, if we are going to appropriately apply the penalty,
we need the inputs to have roughly the same scale.
We therefore cannot just apply or
use logistic regression cv to
tune the elastic net penalty.
This is the major point.
If you need to pre process the inputs before fitting the model,
you cannot perform the pre processing before
splitting the data when you are pre processing
with data dependent transformations.
Data dependent transformations
include standardization, so
centering and scaling,
which we used earlier in the semester,
especially before clustering.
This includes PCA, again, which we used earlier in the semester.
You can apply log transformations,
derive polynomials,
apply square root functions, or
perform any known function transformation
that does not depend on the data before splitting.
So if you need to attempt to remove skew or
asymmetry by applying a log transform, you can do that before splitting.
But if you want to remove the magnitude and scale,
you cannot because the average of a variable,
the standard deviation of a variable, they depend on the data.
So if you calculate those quantities based on all data and
then split into the training and
test sets, well, the test set will have
information shared from the training set.
Instead, the proper way is to have all the data split into training and
test sets, apply the standardization or
the pre processing, calculate the average and
standard deviation, and then apply that
preprocessing on the training set to the test set.
Now, the pre processing of the test
set will be based on the training set,
and nothing about the test set
was used to impact the averages and
scales in the training set.
The data are actually fully separated.
Essentially, you can view this as last week
in week 13 when we set up training and
testing with cross validation and
we did this pretty manually where we were
iterating over all the train test splits.
This function call in this for loop is actually not entirely correct.
This was because last week we weren't concerned about pre processing,
we were just extracting the training and test set.
But if we were doing this completely
fully technically correct,
we would need to pre process the training set and
apply that pre process to the test set
before we fit any of the models.
Appropriately applying the pre
processing within the folds is very tedious.
It is time consuming and
error prone to make sure we execute
the pre processing correctly.
But don't worry, there is a dedicated module to help you.