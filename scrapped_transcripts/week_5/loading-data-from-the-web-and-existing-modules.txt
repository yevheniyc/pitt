Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/Fcmx8/loading-data-from-the-web-and-existing-modules

English
Next. Another action that's pretty common is we
need to read or download from a website.
The data might be located at a web address or URL.
Please go back to this page.
After those four files, there was a link.
If I open that link,
it takes us to a GitHub repository
from the Pandas for Everyone book.
This is a TSV file or tab-separated file.
You can see here on this web page,
instead of having commas after each value,
there's just a space, a tab.
But I'm going to select that web address and copy it.
I'm copying this whole address.
I'm going to come back now to my Jupyter Notebook.
I'm going to define a variable gap URL,
and I will paste the web address within quotes.
I now have a string.
The gap URL, it's a string.
To read in the data,
we provide the URL web address
as a string instead of a file name on our computer.
Let's assign the result to the DataFrame gap_df,
p d.read_CSV, gap_URL.
But I'm not going to run this line of code
because I'm calling read_CSV for comma,
but the file, as we saw is a tab-separated file.
Because we are reading a tab-separated rather than a CSV,
we need to change the sep argument.
Sep stands for what is the separator.
To read in a tab-separated file,
you have to type slash t.
Read_CSV now understands that
it is not using commas to separate the data,
it now correctly reads in the
over 1,700 rows and six columns.
Even though we read it in from a website,
we have a regular pandas DataFrame,
just as if we had read it in
the file directly from our computer.
Lastly, we can read or load data from modules.
We will use data from
modules throughout the ADDM program.
We just need to make sure the module is imported.
Now we will import seaborn as SNS.
This is a module for visualization which we will spend
much more time with over the month to come.
But please, import seaborn as SNS.
You all have it. We will load in the Titanic dataset.
Titanic SNS load dataset
and then type Titanic as a string.
Titanic is a pandas DataFrame.
The purpose here, again,
reading data from files that we
have saved locally onto our computer.
Reading them from Excel,
reading them from different sheets in Excel,
the properties or attributes of the index,
and defining the headers,
reading from CSV files.
How to skip rows and set the max number.
The max number of rows,
by the way, I forgot to mention,
is useful when you
know you're about to read in an enormous dataset.
Maybe there's over 500,000 rows and
you just want to read in the first 10,000 for practice.
That's why this can be useful,
or especially if you have 5,
6, 7 million rows you're reading,
and reading in just
the first 10,000 or so can be helpful.
But then we saw how to read data in from websites,
how to change from CSV to tab-separated,
and lastly, how to read data in from existing modules.