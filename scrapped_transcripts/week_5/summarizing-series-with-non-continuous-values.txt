Source: https://www.coursera.org/learn/mds-introduction-to-data-centric-computing/lecture/w9hzT/summarizing-series-with-non-continuous-values

English
These summary methods that I just showed you are really focused on
summarizing continuous variables, numerics, integers and floats.
But there are also important summary methods associated with unique values.
We can get the number of unique value use for a Pandas series.
My_series.nunique() the nunique
method tells us there are eight unique values.
Now, that's not particularly exciting, probably for this example.
One, because it's small, we could count, but two, we have literally unique numbers.
So it makes sense that the number of unique.
Equals the same as the size.
But knowing the number of unique
values is especially important for
categorical or string variables.
So let's define a new series, my_series_b,
which is a list of letters, so strings.
Here I typed three sequential values of A capital letters,
then B, three sequential values, then C with one, and then two for D.
Now, visually we can see that there are in fact four unique values in this series.
Even though.
There are nine total elements.
So there are nine observations, if you will,
even though we have just four unique values.
This is very important because the number of
unique values does not need to equal the number of elements or size.
Now, why does this happen?
Why is this useful?
This leads to my favorite Pandas method
focuses on dealing with unique values.
Oftentimes we want to count the number
of times a unique value occurs.
Visually, we can see A appears three times, B three times, C once, D twice.
Well, I don't have to do that manually.
I don't need a for loop or anything.
I take my series B and apply the value_counts() method.
And the value_counts() method tells us A appeared 3 times,
B three times, D twice, and D once.
These counts are different, if you will, from just the unique values.
The counts give us more information than just the unique values.
We can get the unique values from value_counts
because the index attribute is the unique values.
So you can see here A, B, C, and D.
Those are the values in the original series.
But the value_counts() method turns them into the index and
the values are now the count.
How many times did each value appear?
If you just want the unique values,
then you can use the unique() method.
So my_series_B.unique(),
we only get the unique values, we don't get the count.
What I was doing here was applying these summary
methods to a Pandas series that we defined ourselves.
But I now want to demonstrate how to.
Summarize individual columns.
Within DataFrames.
This is to reinforce the fact
that COLUMNS are really Pandas
series within a DataFrame.
Let's read in the JOINED data set we created previously.
So df = Pd.read_csv and
the file name was joined_data.csv.
Here's that joined data set.
Access any column and apply summary
methods just like it was a regular
panda series in the environment.
Here, if we ever forget column names, we know about the columns attribute.
If we ever forget the data types, we know about the data types attribute.
But so for example the column A, it's an object or string.
If I access A through the bracket notation.
I can apply the nunique() method,
or I could use the dot notation.
Either way works and I can do this for any column.
We can also apply summary methods like .mean() and
'.std()' to any numeric column.
So the f variable, it's an integer df.F.mean().
Or again, we can use the bracket notation.
Standard deviation.
And just to show it, we can also calculate
the STANDARD ERROR ON THE MEAN or SEM.
So dff.F.std() /
np.sqrt( df.F.size).
But don't worry, all you need to do to apply the sem()
method is call the sem() method.
Pandas has the formula standard deviation divided by
the square root of the number of observations or
the length, it has it embedded within the sem() method.
So anytime you want to get the standard error on the mean,
you don't have to manually calculate it,
standard deviation divided by the square root of number of samples.
All you need to do is call the sem() method.
Okay, essentially,
these are the same ways we applied summary functions to numpy arrays.
Pandas is built on top of NumPy, so
it makes sense that applying summary methods is similar.